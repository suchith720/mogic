# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/20_prediction-analysis.ipynb.

# %% ../nbs/20_prediction-analysis.ipynb 2
import pandas as pd, json, os, pickle, numpy as np, torch, re

from xcai.basics import *
from xcai.analysis import *

def load_config(fname):
    with open(fname, 'r') as file:
        return json.load(file)['data_meta']

def dump_example_text(fname, examples):
    with open(fname, 'w') as file:
        for example in examples:
            for k,v in example.items():
                text = "|".join(v) if isinstance(v, list) else v
                file.write(f"{k} -> {text}\n")
            file.write("\n")

# %% ../nbs/20_prediction-analysis.ipynb 7
if __name__ == '__main__':
    build_block = False
    pkl_dir = '/home/aiscuser/scratch1/datasets/'
    config_file = 'configs/msmarco-entity.json'

    """ Load data """
    pkl_file = f'{pkl_dir}/processed/msmarco_data-entity_distilbert-base-uncased_xcs.pkl'
    if build_block:
        config = load_config(config_file)
        block = XCBlock.from_cfg(config, tokenizer="distilbert-base-uncased",
                sampling_features=[('lbl2data',1)], oversample=False)
        with open(pkl_file, 'wb') as file: pickle.dump(block, file)
        exit()
    else:
        with open(pkl_file, 'rb') as file: block = pickle.load(file)

    n_data = 1000
    pattern = r'^(data|lbl2data|ent2data)_input_text$'
    dset = TextColumns(block.train.dset, pat=r'^(data|lbl2data|ent2data)_input_text$')

    all_idx = np.where(block.train.dset.meta['ent_meta'].data_meta.getnnz(axis=1) > 0)[0]
    rnd_idx = np.random.permutation(len(all_idx))[:n_data]
    idx = all_idx[rnd_idx]

    batch  = [dset[i] for i in idx]
    dump_example_text('examples.txt', batch)
    
