{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d60b51bd-0144-4139-8be5-7602bad6a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp 03_benchmarking_nvembed_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65e00e5c-ff88-425d-a828-7ca5d02215ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874750be-c904-447e-8754-3eefcb9586d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os,torch, torch.multiprocessing as mp, pickle, numpy as np, math, transformers\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from xcai.basics import *\n",
    "\n",
    "from xclib.utils.sparse import retain_topk\n",
    "\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd23053-8908-4615-a47f-96b2039b0cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_MODE'] = 'disabled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44292259-cc09-4bd0-96f3-08206b948924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "os.environ['WANDB_PROJECT']='oakVn_00-wikiseealsotitles'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d7055b-7bcc-4c55-8bac-c9312cb56d23",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Huggingface `NV-Embed-v2` example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9735f180-8557-4bb7-9670-499b74e617b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name_to_instruct = {\"example\": \"Given a question, retrieve passages that answer the question\",}\n",
    "\n",
    "query_prefix = \"Instruct: \"+task_name_to_instruct[\"example\"]+\"\\nQuery: \"\n",
    "queries = [\n",
    "    'are judo throws allowed in wrestling?', \n",
    "    'how to become a radiology technician in michigan?'\n",
    "    ]\n",
    "\n",
    "passage_prefix = \"\"\n",
    "passages = [\n",
    "    \"Since you're reading this, you are probably someone from a judo background or someone who is just wondering how judo techniques can be applied under wrestling rules. So without further ado, let's get to the question. Are Judo throws allowed in wrestling? Yes, judo throws are allowed in freestyle and folkstyle wrestling. You only need to be careful to follow the slam rules when executing judo throws. In wrestling, a slam is lifting and returning an opponent to the mat with unnecessary force.\",\n",
    "    \"Below are the basic steps to becoming a radiologic technologist in Michigan:Earn a high school diploma. As with most careers in health care, a high school education is the first step to finding entry-level employment. Taking classes in math and science, such as anatomy, biology, chemistry, physiology, and physics, can help prepare students for their college studies and future careers.Earn an associate degree. Entry-level radiologic positions typically require at least an Associate of Applied Science. Before enrolling in one of these degree programs, students should make sure it has been properly accredited by the Joint Review Committee on Education in Radiologic Technology (JRCERT).Get licensed or certified in the state of Michigan.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01a5c56d-8cdd-430d-b237-0e2f56faf1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68bace3aba44523b9fae6ba86c7a62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('nvidia/NV-Embed-v2', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6658d681-3b9d-4660-a80f-3d715949f328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scai/phd/aiz218323/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v2/5130cf1daf847c1bacee854a6ef1ca939e747fb2/modeling_nvembed.py:349: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'input_ids': torch.tensor(batch_dict.get('input_ids').to(batch_dict.get('input_ids')).long()),\n",
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "max_length = 32768\n",
    "query_embeddings = model.encode(queries, instruction=query_prefix, max_length=max_length)\n",
    "passage_embeddings = model.encode(passages, instruction=passage_prefix, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abe5ed36-45c4-408e-9f4f-a988229c455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87.42693328857422, 0.46283310651779175], [0.9652641415596008, 86.0372085571289]]\n"
     ]
    }
   ],
   "source": [
    "scores = (query_embeddings @ passage_embeddings.T) * 100\n",
    "print(scores.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e69af54-2aac-4031-aa49-c4ab36bc56ea",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "258d66e0-92d6-4c4d-9edc-06eb30fbf040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets/'\n",
    "data_dir = '/home/scai/phd/aiz218323/Projects/XC_NLG/data'\n",
    "\n",
    "output_dir = '/home/scai/phd/aiz218323/scratch/outputs/mogic/03_benchmarking_nvembed_bm25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cccd8075-3756-4c71-bcba-f339143a1aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('nvidia/NV-Embed-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bec817-b538-41b4-b6c7-72102ea71b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a14386bf-ac0f-4aef-8df2-ac1f92daa75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = f'{pkl_dir}/processed/wikiseealsotitles_data_distilbert-base-uncased_xcs.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ef77a0b-5d20-40eb-9781-b8f690fc7354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealsotitles_data_nv-embed-v2_xcs.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3879382e-324b-4215-8d04-e9b8a7842d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "block = XCBlock.from_cfg(data_dir, 'data', transform_type='xcs', tokenizer='nvidia/NV-Embed-v2', \n",
    "                         sampling_features=[('lbl2data',1)], max_sequence_length=64, oversample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85abc8b-0245-4ee3-9c0d-aa13427dd323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4d042d5a-600c-4ffa-a647-f715a9465667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_func(x):\n",
    "    return f'''Instruct: Given the title of a wikipedia article and the corresponding categories of that article on wikipedia, \\\n",
    "your task is to predict the titles of all articles which are likely to be listed in the see also section of the mentioned article.\\\n",
    "\\nQuery: {x}'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f87b7b1-ca0a-44f5-bf51-c01baed909de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def prompt_func(x):\n",
    "    return f'''Instruct: Given the title of a wikipedia article, your task is to predict the titles of all articles which are \\\n",
    "likely to be listed in the see also section of the mentioned article.\\nQuery: {x}'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbf3cff8-fbd2-41d9-81a0-c6cb0fbef537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "input_text = [prompt_func(o) for o in block.train.dset.data.data_info['input_text']]\n",
    "tokenized_text = tokenizer.batch_encode_plus(input_text, truncation=True, max_length=64)\n",
    "block.train.dset.data.data_info.update(tokenized_text)\n",
    "\n",
    "input_text = [prompt_func(o) for o in block.test.dset.data.data_info['input_text']]\n",
    "tokenized_text = tokenizer.batch_encode_plus(input_text, truncation=True, max_length=64)\n",
    "block.test.dset.data.data_info.update(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633821e8-af3c-47d8-8643-82c00cb8c9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c8e7b8c-b672-4629-9fad-9a310735bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "with open(pkl_file, 'wb') as file: pickle.dump(block, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f9f188f-8cdd-4340-aeef-f7a70b1f6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "with open(pkl_file, 'rb') as file: block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b59ae3d-3f62-4f5e-8534-643ca9492d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7428b36f-55fa-4183-8211-80ddaa8cd89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(block.train.dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a611b67-966c-4f4b-a0a7-fbc559a6cb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'data_idx'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8004d2d7-1bb0-4077-84ed-d03e77bb7e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fd6532a8-9b98-40b2-9f61-d96a161df3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca11573e5e3449fb832e86989923bace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = AutoModel.from_pretrained('nvidia/NV-Embed-v2', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e4866ce8-c774-47f4-83e4-5740d853e514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "o = m(**{'input_ids': batch['data_input_ids'], 'attention_mask': batch['data_attention_mask']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4bcfd6c4-a4ec-4793-8ab2-f8584d3e5c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 47, 4096])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o['sentence_embeddings'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78025432-5290-41be-980a-705aad176290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 47])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['data_input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5943aff7-fd07-4b38-ac46-fdd1058aa0ab",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "901af40b-7b4b-49de-aa9d-bb22fa3015f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from contextlib import nullcontext\n",
    "from xcai.models.modeling_nvembed import NVEmbedModel\n",
    "from transformers.activations import get_activation\n",
    "\n",
    "import torch.nn as nn\n",
    "from xcai.losses import MultiTriplet\n",
    "\n",
    "from xcai.models.modeling_utils import XCModelOutput, Pooling\n",
    "\n",
    "from fastcore.meta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a58768c-6b33-41c3-8afc-04476ba8bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RepresentationHead(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.transform = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size)\n",
    "        self.projector = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = get_activation('relu')\n",
    "        \n",
    "        self.post_init()\n",
    "        \n",
    "    def post_init(self):\n",
    "        torch.nn.init.eye_(self.transform.weight)\n",
    "        torch.nn.init.eye_(self.projector.weight)\n",
    "        \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = self.transform(x)\n",
    "        #x = self.activation(x)\n",
    "        #x = self.layer_norm(x)\n",
    "        #x = self.projector(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22904ff4-148f-45f0-ab25-39dcddf5adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NVM0XXEncoder(NVEmbedModel):\n",
    "    \n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(config)\n",
    "        self.dr_head = RepresentationHead(config)\n",
    "        \n",
    "    @delegates(NVEmbedModel.__call__)\n",
    "    def forward(\n",
    "        self, \n",
    "        input_ids:Optional[torch.Tensor]=None, \n",
    "        attention_mask:Optional[torch.Tensor]=None,\n",
    "        pool_mask: Optional[torch.Tensor]=None,\n",
    "        return_dict: bool=True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        autocast_ctx = torch.autocast if torch.cuda.is_available() else nullcontext\n",
    "        \n",
    "        with autocast_ctx(\"cuda\"):\n",
    "            outputs = self.embedding_model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "            )\n",
    "            embeds = self.latent_attention_model(\n",
    "                outputs.last_hidden_state,\n",
    "                pool_mask,\n",
    "            )\n",
    "            rep = self.dr_head(embeds)\n",
    "        \n",
    "        return outputs, F.normalize(Pooling.mean_pooling(rep, attention_mask), dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d40c992-4ab6-4ff5-b88b-adc53019abba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NVM009(NVEmbedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.embedding_model,encoder.latent_attention_model\"]\n",
    "    \n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 bsz:Optional[int]=None,\n",
    "                 tn_targ:Optional[int]=None,\n",
    "                 margin:Optional[float]=0.3,\n",
    "                 tau:Optional[float]=0.1,\n",
    "                 apply_softmax:Optional[bool]=False,\n",
    "                 n_negatives:Optional[int]=5,\n",
    "                 use_encoder_parallel:Optional[bool]=True,\n",
    "                 *args, **kwargs):\n",
    "        super().__init__(config, *args, **kwargs)\n",
    "        store_attr('use_encoder_parallel')\n",
    "        self.encoder = NVM0XXEncoder(config)\n",
    "        self.loss_fn = MultiTriplet(bsz=bsz, tn_targ=tn_targ, margin=margin, n_negatives=n_negatives, tau=tau, \n",
    "                                    apply_softmax=apply_softmax, reduce='mean')\n",
    "        self.post_init()\n",
    "        self.remap_post_init()\n",
    "        \n",
    "    def init_dr_head(self):\n",
    "        self.encoder.dr_head.post_init()\n",
    "        \n",
    "    def remap_post_init(self):\n",
    "        self.embedding_model = self.encoder.embedding_model\n",
    "        self.latent_attention_model = self.encoder.latent_attention_model\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = nn.DataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_o, data_repr = encoder(data_input_ids, data_attention_mask)\n",
    "        \n",
    "        loss, lbl2data_repr = None, None\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_o, lbl2data_repr = encoder(lbl2data_input_ids, lbl2data_attention_mask)\n",
    "            \n",
    "            loss = self.loss_fn(data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, \n",
    "                                plbl2data_data2ptr, plbl2data_idx, **kwargs)\n",
    "\n",
    "        if not return_dict:\n",
    "            o = (data_repr, lbl2data_repr)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "\n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            data_repr=data_repr,\n",
    "            lbl2data_repr=lbl2data_repr,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e6bd99-4cbc-4d82-820a-0da73f18d23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9fe2682-b1be-47e6-a529-84bc4ef0e22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb244e83f6584584b191e9ce96addfbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of NVM009 were not initialized from the model checkpoint at nvidia/NV-Embed-v2 and are newly initialized: ['encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "model = NVM009.from_pretrained('nvidia/NV-Embed-v2', bsz=1024, margin=0.3, tau=0.1, n_negatives=10, apply_softmax=True, \n",
    "                               use_encoder_parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9297b0b8-a3b9-42a6-b6e1-c3988043aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "o = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90d157bb-f47b-4a01-b248-9e2307f8c04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0333, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cb6d58-ab40-4604-9bcd-b22a6db2fa57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7c9030f3-5ee6-46c6-9e9e-c99fde45d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    o = model(**batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "561660db-e379-417c-ab7b-44830cbf8f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/3800815954.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     o = model(**batch)\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b\n",
      "ipdb>  b model.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 5 at /tmp/ipykernel_5460/4263273048.py:30\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.encoder.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 6 at /tmp/ipykernel_5460/1004996700.py:7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(43)forward()\n",
      "     41         **kwargs\n",
      "     42     ):\n",
      "---> 43         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     44 \n",
      "     45         if self.use_encoder_parallel:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(45)forward()\n",
      "     43         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     44 \n",
      "---> 45         if self.use_encoder_parallel:\n",
      "     46             encoder = nn.DataParallel(module=self.encoder)\n",
      "     47         else: encoder = self.encoder\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(47)forward()\n",
      "     45         if self.use_encoder_parallel:\n",
      "     46             encoder = nn.DataParallel(module=self.encoder)\n",
      "---> 47         else: encoder = self.encoder\n",
      "     48 \n",
      "     49         data_o, data_repr = encoder(data_input_ids, data_attention_mask)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(49)forward()\n",
      "     47         else: encoder = self.encoder\n",
      "     48 \n",
      "---> 49         data_o, data_repr = encoder(data_input_ids, data_attention_mask)\n",
      "     50 \n",
      "     51         loss, lbl2data_repr = None, None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/1004996700.py(16)forward()\n",
      "     14         **kwargs\n",
      "     15     ):\n",
      "---> 16         autocast_ctx = torch.autocast if torch.cuda.is_available() else nullcontext\n",
      "     17 \n",
      "     18         with autocast_ctx(\"cuda\"):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/1004996700.py(18)forward()\n",
      "     16         autocast_ctx = torch.autocast if torch.cuda.is_available() else nullcontext\n",
      "     17 \n",
      "---> 18         with autocast_ctx(\"cuda\"):\n",
      "     19             outputs = self.embedding_model(\n",
      "     20                 input_ids=input_ids,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/1004996700.py(19)forward()\n",
      "     17 \n",
      "     18         with autocast_ctx(\"cuda\"):\n",
      "---> 19             outputs = self.embedding_model(\n",
      "     20                 input_ids=input_ids,\n",
      "     21                 attention_mask=attention_mask,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/1004996700.py(20)forward()\n",
      "     18         with autocast_ctx(\"cuda\"):\n",
      "     19             outputs = self.embedding_model(\n",
      "---> 20                 input_ids=input_ids,\n",
      "     21                 attention_mask=attention_mask,\n",
      "     22             )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/1004996700.py(21)forward()\n",
      "     19             outputs = self.embedding_model(\n",
      "     20                 input_ids=input_ids,\n",
      "---> 21                 attention_mask=attention_mask,\n",
      "     22             )\n",
      "     23             embeds = self.latent_attention_model(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/1004996700.py(19)forward()\n",
      "     17 \n",
      "     18         with autocast_ctx(\"cuda\"):\n",
      "---> 19             outputs = self.embedding_model(\n",
      "     20                 input_ids=input_ids,\n",
      "     21                 attention_mask=attention_mask,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/1004996700.py(23)forward()\n",
      "     21                 attention_mask=attention_mask,\n",
      "     22             )\n",
      "---> 23             embeds = self.latent_attention_model(\n",
      "     24                 outputs.last_hidden_state,\n",
      "     25                 pool_mask,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/1004996700.py(24)forward()\n",
      "     22             )\n",
      "     23             embeds = self.latent_attention_model(\n",
      "---> 24                 outputs.last_hidden_state,\n",
      "     25                 pool_mask,\n",
      "     26             )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/1004996700.py(25)forward()\n",
      "     23             embeds = self.latent_attention_model(\n",
      "     24                 outputs.last_hidden_state,\n",
      "---> 25                 pool_mask,\n",
      "     26             )\n",
      "     27             rep = self.dr_head(embeds)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/1004996700.py(23)forward()\n",
      "     21                 attention_mask=attention_mask,\n",
      "     22             )\n",
      "---> 23             embeds = self.latent_attention_model(\n",
      "     24                 outputs.last_hidden_state,\n",
      "     25                 pool_mask,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/1004996700.py(27)forward()\n",
      "     25                 pool_mask,\n",
      "     26             )\n",
      "---> 27             rep = self.dr_head(embeds)\n",
      "     28 \n",
      "     29         return outputs, F.normalize(Pooling.mean_pooling(rep, attention_mask), dim=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  torch.nn.Identity()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.dr_head = torch.nn.Identity()\n",
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/1004996700.py(29)forward()\n",
      "     26             )\n",
      "     27             rep = self.dr_head(embeds)\n",
      "     28 \n",
      "---> 29         return outputs, F.normalize(Pooling.mean_pooling(rep, attention_mask), dim=1)\n",
      "     30 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  rep.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 47, 4096])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  rep\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.7431e+00, -1.6791e+00,  1.5581e+00,  ..., -2.8492e+00,\n",
      "           2.5091e-02,  5.8852e-01],\n",
      "         [-5.7464e+00, -7.0676e+00, -5.2332e-01,  ..., -1.0842e+00,\n",
      "          -3.1414e+00,  2.7235e+00],\n",
      "         [ 9.3980e-01, -7.7707e+00,  8.3928e+00,  ..., -1.5965e-01,\n",
      "           1.6055e+00,  1.3432e+01],\n",
      "         ...,\n",
      "         [-7.6854e+00, -2.5286e+00,  4.4305e+00,  ..., -6.1472e+00,\n",
      "          -2.4904e+00,  2.9824e+00],\n",
      "         [-5.0773e+00,  1.8037e+00,  2.7820e+00,  ..., -1.3706e-02,\n",
      "           3.6260e+00,  7.7177e+00],\n",
      "         [-5.5169e+00,  1.3697e+00,  6.0640e+00,  ...,  3.9210e+00,\n",
      "           1.3565e+00,  7.5124e+00]],\n",
      "\n",
      "        [[-2.9780e+00, -7.2495e-01,  9.7949e-01,  ..., -2.5192e+00,\n",
      "          -8.6461e-01,  5.7428e-01],\n",
      "         [-7.6525e+00, -3.4010e+00,  8.5716e+00,  ...,  3.2418e+00,\n",
      "           8.1959e-01,  1.0069e+01],\n",
      "         [ 2.7054e-01, -7.2799e+00,  8.2326e+00,  ...,  6.8420e-01,\n",
      "           3.3271e+00,  1.2162e+01],\n",
      "         ...,\n",
      "         [-8.6517e+00,  2.1012e+00,  1.0997e+01,  ...,  2.3738e+00,\n",
      "          -1.1212e+00,  1.2456e+01],\n",
      "         [-7.1906e+00,  4.3065e+00,  1.1001e+01,  ...,  5.8941e+00,\n",
      "          -3.7087e+00,  1.3337e+01],\n",
      "         [-8.0125e+00,  4.1271e+00,  1.1288e+01,  ...,  4.8953e+00,\n",
      "          -4.0463e+00,  1.2763e+01]],\n",
      "\n",
      "        [[-8.4437e-01, -9.6528e-01,  1.5927e-01,  ..., -3.2258e+00,\n",
      "           1.9604e-01, -2.8622e-01],\n",
      "         [ 5.2570e+00, -4.3735e+00, -7.6507e+00,  ...,  2.0091e+00,\n",
      "           4.2209e+00, -1.5894e+00],\n",
      "         [ 9.7498e-01, -7.4523e+00,  8.2524e+00,  ...,  8.0097e-01,\n",
      "           3.3815e+00,  1.2210e+01],\n",
      "         ...,\n",
      "         [ 5.3322e-01,  6.6110e+00,  1.5874e-01,  ...,  2.4147e+00,\n",
      "           6.3582e+00, -4.6509e+00],\n",
      "         [ 4.1524e+00,  3.6245e+00,  3.1045e+00,  ...,  1.2756e+00,\n",
      "           1.1767e-01, -3.0367e+00],\n",
      "         [ 4.8945e+00,  3.6220e+00, -8.6986e-01,  ...,  3.0663e+00,\n",
      "           1.1355e+00,  7.1029e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.5227e+00, -6.5858e-01,  9.8224e-01,  ..., -2.0494e+00,\n",
      "          -5.1810e-01, -5.9553e-02],\n",
      "         [ 7.6511e+00, -5.7239e+00,  2.2693e+00,  ...,  2.4401e+00,\n",
      "           3.0544e+00, -2.9257e+00],\n",
      "         [ 1.0847e+00, -6.9776e+00,  9.0676e+00,  ...,  2.7494e-01,\n",
      "           2.7528e+00,  1.2268e+01],\n",
      "         ...,\n",
      "         [ 4.1231e+00, -2.0979e-01,  4.5646e+00,  ..., -7.4255e+00,\n",
      "          -2.0883e-01,  7.4598e+00],\n",
      "         [ 7.0478e+00,  1.1371e+00,  3.9444e+00,  ...,  4.1339e+00,\n",
      "          -1.6563e+00,  3.7352e+00],\n",
      "         [ 3.0795e+00,  4.9098e+00,  3.8011e+00,  ...,  5.7890e+00,\n",
      "           1.9550e+00,  2.0509e+00]],\n",
      "\n",
      "        [[-2.1684e+00, -1.0380e+00, -4.3039e-01,  ..., -2.9167e+00,\n",
      "          -7.7245e-01, -3.4179e-01],\n",
      "         [ 3.1030e+00, -7.8085e+00, -1.0332e+01,  ...,  2.6256e+00,\n",
      "          -5.7952e+00, -1.0830e+01],\n",
      "         [ 2.1963e+00, -6.5813e+00,  8.6750e+00,  ..., -3.0178e-02,\n",
      "           3.1021e+00,  1.2005e+01],\n",
      "         ...,\n",
      "         [-6.0153e+00, -4.3663e+00, -3.1371e+00,  ...,  7.2886e-01,\n",
      "          -1.5869e+01, -6.0683e+00],\n",
      "         [-1.5256e+00,  5.2917e+00, -9.0260e+00,  ...,  3.6722e+00,\n",
      "          -8.0522e+00, -7.8077e+00],\n",
      "         [-3.4067e+00,  1.8828e+00, -4.5200e+00,  ...,  8.3513e-01,\n",
      "          -3.9212e+00, -4.9405e+00]],\n",
      "\n",
      "        [[-1.3939e+00, -7.0603e-01, -6.1711e-02,  ..., -2.8282e+00,\n",
      "          -2.0991e-01,  2.8678e-01],\n",
      "         [ 3.5598e+00, -6.1652e+00, -4.5658e+00,  ..., -2.0665e+00,\n",
      "          -4.2480e+00,  3.4855e+00],\n",
      "         [ 7.6025e-01, -6.1465e+00,  7.8365e+00,  ...,  5.2141e-01,\n",
      "           3.0376e+00,  1.2942e+01],\n",
      "         ...,\n",
      "         [ 4.0132e+00,  6.0853e+00,  3.8269e+00,  ..., -2.2366e+00,\n",
      "          -2.9248e+00,  1.3718e+00],\n",
      "         [ 9.1740e+00,  4.5686e+00,  2.3494e+00,  ...,  2.1770e+00,\n",
      "          -1.0476e+00,  7.4055e+00],\n",
      "         [ 9.2706e+00,  4.7896e+00,  2.6361e+00,  ...,  1.5882e+00,\n",
      "          -7.5554e-01,  8.4863e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  rep.dtype\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  rep.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 47, 4096])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     24                 outputs.last_hidden_state,\n",
      "     25                 pool_mask,\n",
      "     26             )\n",
      "     27             rep = self.dr_head(embeds)\n",
      "     28 \n",
      "---> 29         return outputs, F.normalize(Pooling.mean_pooling(rep, attention_mask), dim=1)\n",
      "     30 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  attention_mask.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 47])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  attention_mask.dtype\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  xx = Pooling.mean_pooling(rep, attention_mask)\n",
      "ipdb>  xx.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4096])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  xx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2438, -1.9693,  8.1109,  ...,  0.9516, -0.6723,  8.0693],\n",
      "        [-0.9251, -0.3462,  9.0514,  ...,  1.3616, -2.7477, 10.3213],\n",
      "        [ 6.9295, -0.1380,  6.1666,  ..., -0.9735,  0.6603,  4.2732],\n",
      "        ...,\n",
      "        [ 2.9733, -0.8720,  7.4740,  ...,  1.1270, -0.8351,  5.5786],\n",
      "        [ 0.6036, -0.7551,  1.2821,  ...,  0.3292, -3.1174,  1.5676],\n",
      "        [ 7.2001,  1.4673,  4.1804,  ..., -1.9378, -1.5556,  7.7727]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  xx = F.normalize(Pooling.mean_pooling(rep, attention_mask), dim=1)\n",
      "ipdb>  xx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0009, -0.0071,  0.0293,  ...,  0.0034, -0.0024,  0.0292],\n",
      "        [-0.0033, -0.0012,  0.0322,  ...,  0.0048, -0.0098,  0.0367],\n",
      "        [ 0.0246, -0.0005,  0.0219,  ..., -0.0035,  0.0023,  0.0152],\n",
      "        ...,\n",
      "        [ 0.0109, -0.0032,  0.0274,  ...,  0.0041, -0.0031,  0.0204],\n",
      "        [ 0.0022, -0.0028,  0.0047,  ...,  0.0012, -0.0114,  0.0057],\n",
      "        [ 0.0260,  0.0053,  0.0151,  ..., -0.0070, -0.0056,  0.0280]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  xx.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4096])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  torch.norm(xx, dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(BaseModelOutp...tentions=None), tensor([[-0.0...DivBackward0>))\n",
      "> /tmp/ipykernel_5460/1004996700.py(29)forward()\n",
      "     26             )\n",
      "     27             rep = self.dr_head(embeds)\n",
      "     28 \n",
      "---> 29         return outputs, F.normalize(Pooling.mean_pooling(rep, attention_mask), dim=1)\n",
      "     30 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  xx = F.normalize(Pooling.mean_pooling(rep, attention_mask), dim=1)\n",
      "ipdb>  xx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0009, -0.0071,  0.0293,  ...,  0.0034, -0.0024,  0.0292],\n",
      "        [-0.0033, -0.0012,  0.0322,  ...,  0.0048, -0.0098,  0.0367],\n",
      "        [ 0.0246, -0.0005,  0.0219,  ..., -0.0035,  0.0023,  0.0152],\n",
      "        ...,\n",
      "        [ 0.0109, -0.0032,  0.0274,  ...,  0.0041, -0.0031,  0.0204],\n",
      "        [ 0.0022, -0.0028,  0.0047,  ...,  0.0012, -0.0114,  0.0057],\n",
      "        [ 0.0260,  0.0053,  0.0151,  ..., -0.0070, -0.0056,  0.0280]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(51)forward()\n",
      "     49         data_o, data_repr = encoder(data_input_ids, data_attention_mask)\n",
      "     50 \n",
      "---> 51         loss, lbl2data_repr = None, None\n",
      "     52         if lbl2data_input_ids is not None:\n",
      "     53             lbl2data_o, lbl2data_repr = encoder(lbl2data_input_ids, lbl2data_attention_mask)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_repr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0009, -0.0071,  0.0293,  ...,  0.0034, -0.0024,  0.0292],\n",
      "        [-0.0033, -0.0012,  0.0322,  ...,  0.0048, -0.0098,  0.0367],\n",
      "        [ 0.0246, -0.0005,  0.0219,  ..., -0.0035,  0.0023,  0.0152],\n",
      "        ...,\n",
      "        [ 0.0109, -0.0032,  0.0274,  ...,  0.0041, -0.0031,  0.0204],\n",
      "        [ 0.0022, -0.0028,  0.0047,  ...,  0.0012, -0.0114,  0.0057],\n",
      "        [ 0.0260,  0.0053,  0.0151,  ..., -0.0070, -0.0056,  0.0280]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(52)forward()\n",
      "     50 \n",
      "     51         loss, lbl2data_repr = None, None\n",
      "---> 52         if lbl2data_input_ids is not None:\n",
      "     53             lbl2data_o, lbl2data_repr = encoder(lbl2data_input_ids, lbl2data_attention_mask)\n",
      "     54 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(53)forward()\n",
      "     51         loss, lbl2data_repr = None, None\n",
      "     52         if lbl2data_input_ids is not None:\n",
      "---> 53             lbl2data_o, lbl2data_repr = encoder(lbl2data_input_ids, lbl2data_attention_mask)\n",
      "     54 \n",
      "     55             loss = self.loss_fn(data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/1004996700.py(16)forward()\n",
      "     14         **kwargs\n",
      "     15     ):\n",
      "---> 16         autocast_ctx = torch.autocast if torch.cuda.is_available() else nullcontext\n",
      "     17 \n",
      "     18         with autocast_ctx(\"cuda\"):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/1004996700.py(18)forward()\n",
      "     16         autocast_ctx = torch.autocast if torch.cuda.is_available() else nullcontext\n",
      "     17 \n",
      "---> 18         with autocast_ctx(\"cuda\"):\n",
      "     19             outputs = self.embedding_model(\n",
      "     20                 input_ids=input_ids,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(BaseModelOutp...tentions=None), tensor([[-0.0...DivBackward0>))\n",
      "> /tmp/ipykernel_5460/1004996700.py(29)forward()\n",
      "     26             )\n",
      "     27             rep = self.dr_head(embeds)\n",
      "     28 \n",
      "---> 29         return outputs, F.normalize(Pooling.mean_pooling(rep, attention_mask), dim=1)\n",
      "     30 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  rep\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ -4.2426,  -1.9024,  -1.6038,  ...,  -3.0897,   0.3716,  -2.5756],\n",
      "         [ -5.6590,   1.9587,  -4.9972,  ...,   0.5762,   3.0439,   2.9400],\n",
      "         [ -7.4704,  -1.7220,   1.1262,  ...,  -6.5749,  -0.9878,  -2.3778],\n",
      "         ...,\n",
      "         [ -6.6515,   3.4415,  -2.5020,  ...,   6.7126,   4.5213,   0.8689],\n",
      "         [ -6.5692,   3.0849,  -2.4015,  ...,   6.2121,   4.5357,   0.9597],\n",
      "         [ -6.3492,   2.9202,  -2.3292,  ...,   6.1498,   4.2114,   0.9382]],\n",
      "\n",
      "        [[ -4.7313,  -1.4236,  -0.8584,  ...,  -3.0321,  -0.8166,  -2.0879],\n",
      "         [  5.0878,  -0.5830,   8.3816,  ...,  -2.1120,  -1.0463,   4.9551],\n",
      "         [ -8.4701,   3.0259,   9.7580,  ...,  -0.6330,  -0.3507,   5.6358],\n",
      "         ...,\n",
      "         [ -5.9997,   3.7220,   1.0707,  ...,   3.9083,  -0.0986,   3.9553],\n",
      "         [ -6.1704,   3.8101,   0.9107,  ...,   3.9931,   0.1715,   3.7594],\n",
      "         [ -6.1943,   3.7836,   0.8842,  ...,   4.1534,   0.2901,   3.6224]],\n",
      "\n",
      "        [[ -3.5082,  -1.1946,  -1.5158,  ...,  -1.7190,  -0.3072,  -1.8676],\n",
      "         [ -4.1205,   3.0449,   3.7041,  ...,  -3.0281,  -4.7038,  -0.3775],\n",
      "         [ -4.4360,   2.5674,   1.7171,  ...,   2.6144,   5.9900,  -6.9993],\n",
      "         ...,\n",
      "         [ -3.7969,   5.8150,  -3.6733,  ...,   0.6887,   5.0905,   0.4580],\n",
      "         [ -3.6010,   5.5378,  -3.8292,  ...,   0.8216,   5.0306,   0.1537],\n",
      "         [ -3.2876,   5.3364,  -3.8892,  ...,   0.7565,   5.1470,  -0.1277]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -4.7346,  -1.1180,  -1.0287,  ...,  -1.6520,  -0.5732,  -2.1307],\n",
      "         [ -7.3758,   1.5959,   0.3294,  ...,   0.1477,   5.9692,   0.2567],\n",
      "         [  2.0510,  -0.1398,   2.1312,  ...,  -6.8238,  -0.2637,   2.8492],\n",
      "         ...,\n",
      "         [ -3.7927,   3.5275,  -0.1425,  ...,   6.0720,   4.0217,  -1.7122],\n",
      "         [ -3.5090,   3.4597,  -0.1720,  ...,   5.6384,   4.2590,  -1.7032],\n",
      "         [ -3.1820,   3.7975,   0.0688,  ...,   5.5505,   4.4764,  -2.0088]],\n",
      "\n",
      "        [[ -3.5269,   0.5894,  -1.0338,  ...,   0.2008,  -1.7692,  -3.7312],\n",
      "         [ -3.7411,   1.0976,  -1.8084,  ...,  -3.1157,  -6.6730,  -4.4493],\n",
      "         [ -3.6541,   4.7400,  -5.2392,  ...,  -5.8525,   3.8730,  -0.8427],\n",
      "         ...,\n",
      "         [ -2.6239,   5.6861,  -1.0471,  ...,   5.5356, -10.5476,  -6.4045],\n",
      "         [ -5.3020,   1.2649,  -1.6209,  ...,   6.5244,  -3.1942,  -5.7221],\n",
      "         [  2.1260,   3.3814,  -2.0580,  ...,   1.3901,  -0.9468,  -5.5330]],\n",
      "\n",
      "        [[ -3.8745,  -0.8732,  -1.3145,  ...,  -2.9698,   0.0159,  -1.6769],\n",
      "         [  2.2254,  -0.1762,  -4.2359,  ...,  -1.8075,   5.4267,   3.7639],\n",
      "         [  1.4334,   0.8488,   2.4616,  ...,  -3.6015,  -0.5887,  -2.7849],\n",
      "         ...,\n",
      "         [  0.7615,   4.7311,   1.4047,  ...,   3.6066,   1.9256,   0.1775],\n",
      "         [  0.5674,   4.5142,   1.3255,  ...,   3.6394,   1.8770,   0.2424],\n",
      "         [  0.4264,   4.3944,   1.3498,  ...,   3.7098,   1.6001,   0.2079]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  F.normalize(Pooling.mean_pooling(rep, attention_mask), dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0283, -0.0004, -0.0078,  ..., -0.0162,  0.0121, -0.0020],\n",
      "        [-0.0134,  0.0017,  0.0285,  ..., -0.0095, -0.0037,  0.0140],\n",
      "        [-0.0187,  0.0083,  0.0042,  ..., -0.0048,  0.0006, -0.0172],\n",
      "        ...,\n",
      "        [-0.0070, -0.0051, -0.0001,  ..., -0.0058,  0.0058,  0.0011],\n",
      "        [-0.0183,  0.0182, -0.0097,  ...,  0.0027, -0.0196, -0.0172],\n",
      "        [-0.0004, -0.0003, -0.0051,  ..., -0.0139,  0.0081, -0.0012]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(55)forward()\n",
      "     53             lbl2data_o, lbl2data_repr = encoder(lbl2data_input_ids, lbl2data_attention_mask)\n",
      "     54 \n",
      "---> 55             loss = self.loss_fn(data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, \n",
      "     56                                 plbl2data_data2ptr, plbl2data_idx, **kwargs)\n",
      "     57 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  lbl2data_repr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0283, -0.0004, -0.0078,  ..., -0.0162,  0.0121, -0.0020],\n",
      "        [-0.0134,  0.0017,  0.0285,  ..., -0.0095, -0.0037,  0.0140],\n",
      "        [-0.0187,  0.0083,  0.0042,  ..., -0.0048,  0.0006, -0.0172],\n",
      "        ...,\n",
      "        [-0.0070, -0.0051, -0.0001,  ..., -0.0058,  0.0058,  0.0011],\n",
      "        [-0.0183,  0.0182, -0.0097,  ...,  0.0027, -0.0196, -0.0172],\n",
      "        [-0.0004, -0.0003, -0.0051,  ..., -0.0139,  0.0081, -0.0012]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(56)forward()\n",
      "     54 \n",
      "     55             loss = self.loss_fn(data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, \n",
      "---> 56                                 plbl2data_data2ptr, plbl2data_idx, **kwargs)\n",
      "     57 \n",
      "     58         if not return_dict:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(55)forward()\n",
      "     53             lbl2data_o, lbl2data_repr = encoder(lbl2data_input_ids, lbl2data_attention_mask)\n",
      "     54 \n",
      "---> 55             loss = self.loss_fn(data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, \n",
      "     56                                 plbl2data_data2ptr, plbl2data_idx, **kwargs)\n",
      "     57 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(56)forward()\n",
      "     54 \n",
      "     55             loss = self.loss_fn(data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, \n",
      "---> 56                                 plbl2data_data2ptr, plbl2data_idx, **kwargs)\n",
      "     57 \n",
      "     58         if not return_dict:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(55)forward()\n",
      "     53             lbl2data_o, lbl2data_repr = encoder(lbl2data_input_ids, lbl2data_attention_mask)\n",
      "     54 \n",
      "---> 55             loss = self.loss_fn(data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, \n",
      "     56                                 plbl2data_data2ptr, plbl2data_idx, **kwargs)\n",
      "     57 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(58)forward()\n",
      "     56                                 plbl2data_data2ptr, plbl2data_idx, **kwargs)\n",
      "     57 \n",
      "---> 58         if not return_dict:\n",
      "     59             o = (data_repr, lbl2data_repr)\n",
      "     60             return ((loss,) + o) if loss is not None else o\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0140, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(62)forward()\n",
      "     60             return ((loss,) + o) if loss is not None else o\n",
      "     61 \n",
      "---> 62         return XCModelOutput(\n",
      "     63             loss=loss,\n",
      "     64             data_repr=data_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(63)forward()\n",
      "     61 \n",
      "     62         return XCModelOutput(\n",
      "---> 63             loss=loss,\n",
      "     64             data_repr=data_repr,\n",
      "     65             lbl2data_repr=lbl2data_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(64)forward()\n",
      "     62         return XCModelOutput(\n",
      "     63             loss=loss,\n",
      "---> 64             data_repr=data_repr,\n",
      "     65             lbl2data_repr=lbl2data_repr,\n",
      "     66         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(65)forward()\n",
      "     62         return XCModelOutput(\n",
      "     63             loss=loss,\n",
      "     64             data_repr=data_repr,\n",
      "---> 65             lbl2data_repr=lbl2data_repr,\n",
      "     66         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5460/4263273048.py(62)forward()\n",
      "     60             return ((loss,) + o) if loss is not None else o\n",
      "     61 \n",
      "---> 62         return XCModelOutput(\n",
      "     63             loss=loss,\n",
      "     64             data_repr=data_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "XCModelOutput...sed_repr=None)\n",
      "> /tmp/ipykernel_5460/4263273048.py(62)forward()\n",
      "     60             return ((loss,) + o) if loss is not None else o\n",
      "     61 \n",
      "---> 62         return XCModelOutput(\n",
      "     63             loss=loss,\n",
      "     64             data_repr=data_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> /tmp/ipykernel_5460/3800815954.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     o = model(**batch)\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  o.loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0140, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/IPython/core/displayhook.py(258)__call__()\n",
      "    256         sys.stdout.flush()\n",
      "    257 \n",
      "--> 258     def __call__(self, result=None):\n",
      "    259         \"\"\"Printing with history cache management.\n",
      "    260 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c87285-5a57-4ee0-82ba-f1dfbadb4c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "653ee19c-38b0-48e4-8613-54b8d447cccf",
   "metadata": {},
   "source": [
    "## Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67be8d-d2b0-40d2-a772-8d068ad99a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='10396500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [      21/10396500 10:23 < 94728:46:30, 0.03 it/s, Epoch 0.00/300]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@10</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>N@1</th>\n",
       "      <th>N@10</th>\n",
       "      <th>N@3</th>\n",
       "      <th>N@5</th>\n",
       "      <th>Psp@1</th>\n",
       "      <th>Psp@10</th>\n",
       "      <th>Psp@3</th>\n",
       "      <th>Psp@5</th>\n",
       "      <th>Psn@1</th>\n",
       "      <th>Psn@10</th>\n",
       "      <th>Psn@3</th>\n",
       "      <th>Psn@5</th>\n",
       "      <th>R@200</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.086276</td>\n",
       "      <td>0.175101</td>\n",
       "      <td>0.056812</td>\n",
       "      <td>0.115025</td>\n",
       "      <td>0.087132</td>\n",
       "      <td>0.175101</td>\n",
       "      <td>0.194849</td>\n",
       "      <td>0.173305</td>\n",
       "      <td>0.180583</td>\n",
       "      <td>0.163741</td>\n",
       "      <td>0.209324</td>\n",
       "      <td>0.168619</td>\n",
       "      <td>0.180018</td>\n",
       "      <td>0.163741</td>\n",
       "      <td>0.201765</td>\n",
       "      <td>0.174354</td>\n",
       "      <td>0.185467</td>\n",
       "      <td>0.429889</td>\n",
       "      <td>0.235065</td>\n",
       "      <td>0.384685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3840' max='8876' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3840/8876 03:31 < 04:38, 18.11 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9dddc6d9a64058b82b2ca61ae6b27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15617 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e7320ceba542bc8a85e6e26205e3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15617 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    build_block = True\n",
    "    pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets/'\n",
    "    data_dir = '/home/scai/phd/aiz218323/Projects/XC_NLG/data'\n",
    "    \n",
    "    output_dir = '/home/scai/phd/aiz218323/scratch/outputs/mogic/00_oak-for-wikiseealsotitles-trained-with-linker-predictions'\n",
    "    meta_embed_file = '/home/aiscuser/scratch/OGB_Weights/LF-WikiSeeAlsoTitles-320K/emb_weights.npy'\n",
    "\n",
    "    \"\"\" Load data \"\"\"\n",
    "    pkl_file = f'{pkl_dir}/processed/wikiseealsotitles_data-lnk_distilbert-base-uncased_xcs.pkl'\n",
    "\n",
    "    if build_block:\n",
    "        block = XCBlock.from_cfg(data_dir, 'data_lnk', transform_type='xcs', tokenizer='distilbert-base-uncased', \n",
    "                                 sampling_features=[('lbl2data',4), ('lnk2data',3)], oversample=False)\n",
    "        with open(pkl_file, 'wb') as file: pickle.dump(block, file)\n",
    "        exit()\n",
    "    else:\n",
    "        with open(pkl_file, 'rb') as file: block = pickle.load(file)\n",
    "    \n",
    "    \"\"\" Prune metadata \"\"\"\n",
    "    data_meta = retain_topk(block.train.dset.meta['lnk_meta'].data_meta, k=5)\n",
    "    lbl_meta = block.train.dset.meta['lnk_meta'].lbl_meta\n",
    "    block.train.dset.meta['lnk_meta'].update_meta_matrix(data_meta, lbl_meta)\n",
    "    \n",
    "    data_meta = retain_topk(block.test.dset.meta['lnk_meta'].data_meta, k=3)\n",
    "    lbl_meta = block.test.dset.meta['lnk_meta'].lbl_meta\n",
    "    block.test.dset.meta['lnk_meta'].update_meta_matrix(data_meta, lbl_meta)\n",
    "\n",
    "    block.collator.tfms.tfms[0].sampling_features = [('lbl2data',4),('lnk2data',3)]\n",
    "    block.collator.tfms.tfms[0].oversample = False\n",
    "    \n",
    "    block.train.dset.meta['lnk_meta'].meta_info = None\n",
    "    block.test.dset.meta['lnk_meta'].meta_info = None\n",
    "\n",
    "    \"\"\" Training arguements \"\"\"\n",
    "    args = XCLearningArguments(\n",
    "        output_dir=output_dir,\n",
    "        logging_first_step=True,\n",
    "        per_device_train_batch_size=800,\n",
    "        per_device_eval_batch_size=800,\n",
    "        representation_num_beams=200,\n",
    "        representation_accumulation_steps=10,\n",
    "        save_strategy=\"steps\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=5000,\n",
    "        save_steps=5000,\n",
    "        save_total_limit=5,\n",
    "        num_train_epochs=300,\n",
    "        predict_with_representation=True,\n",
    "        adam_epsilon=1e-6,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        learning_rate=2e-4,\n",
    "        representation_search_type='BRUTEFORCE',\n",
    "        \n",
    "        output_representation_attribute='data_fused_repr',\n",
    "        label_representation_attribute='data_repr',\n",
    "        metadata_representation_attribute='data_repr',\n",
    "        data_augmentation_attribute='data_repr',\n",
    "        representation_attribute='data_fused_repr',\n",
    "        clustering_representation_attribute='data_fused_repr',\n",
    "    \n",
    "        group_by_cluster=True,\n",
    "        num_clustering_warmup_epochs=10,\n",
    "        num_cluster_update_epochs=5,\n",
    "        num_cluster_size_update_epochs=25,\n",
    "        use_data_metadata_for_clustering=True,\n",
    "        clustering_type='EXPO',\n",
    "        minimum_cluster_size=2,\n",
    "        maximum_cluster_size=1600,\n",
    "\n",
    "        metric_for_best_model='P@1',\n",
    "        load_best_model_at_end=True,\n",
    "        target_indices_key='plbl2data_idx',\n",
    "        target_pointer_key='plbl2data_data2ptr',\n",
    "        \n",
    "        use_distributional_representation=False,\n",
    "        use_encoder_parallel=True,\n",
    "        max_grad_norm=None, \n",
    "        fp16=True,\n",
    "        \n",
    "        label_names=['lbl2data_idx', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'lnk2data_idx'],\n",
    "        \n",
    "        prune_metadata=False,\n",
    "        num_metadata_prune_warmup_epochs=10,\n",
    "        num_metadata_prune_epochs=5,\n",
    "        metadata_prune_batch_size=2048,\n",
    "        prune_metadata_names=['lnk_meta'],\n",
    "        use_data_metadata_for_pruning=True,\n",
    "    \n",
    "        predict_with_augmentation=False,\n",
    "        use_augmentation_index_representation=True,\n",
    "    \n",
    "        data_aug_meta_name='lnk',\n",
    "        augmentation_num_beams=None,\n",
    "        data_aug_prefix='lnk',\n",
    "        use_label_metadata=False,\n",
    "        \n",
    "        data_meta_batch_size=2048,\n",
    "        augment_metadata=False,\n",
    "        num_metadata_augment_warmup_epochs=10,\n",
    "        num_metadata_augment_epochs=5,\n",
    "    \n",
    "        use_cpu_for_searching=False,\n",
    "        use_cpu_for_clustering=True,\n",
    "    )\n",
    "\n",
    "    \"\"\" model \"\"\"\n",
    "    bsz = max(args.per_device_train_batch_size, args.per_device_eval_batch_size)*torch.cuda.device_count()\n",
    "    model = OAK001.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=bsz, num_batch_labels=5000, \n",
    "                                   margin=0.3, num_negatives=10, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                                   data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                                   data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                                   \n",
    "                                   num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000,\n",
    "                                   \n",
    "                                   calib_margin=0.05, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                                   calib_loss_weight=0.1, use_calib_loss=False,\n",
    "    \n",
    "                                   use_query_loss=True,\n",
    "    \n",
    "                                   meta_loss_weight=0.0, \n",
    "                                   \n",
    "                                   fusion_loss_weight=0.0, use_fusion_loss=False,\n",
    "                                   \n",
    "                                   use_encoder_parallel=True)\n",
    "    \n",
    "    model.init_retrieval_head()\n",
    "    model.init_cross_head()\n",
    "    model.init_meta_embeddings()\n",
    "    \n",
    "    meta_embeddings = np.load(meta_embed_file)\n",
    "    model.encoder.set_pretrained_meta_embeddings(torch.tensor(meta_embeddings, dtype=torch.float32))\n",
    "    model.encoder.freeze_pretrained_meta_embeddings()\n",
    "    \n",
    "    \"\"\" Training \"\"\"\n",
    "    metric = PrecRecl(block.n_lbl, block.test.data_lbl_filterer, prop=block.train.dset.data.data_lbl,\n",
    "                      pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])\n",
    "\n",
    "    learn = XCLearner(\n",
    "        model=model, \n",
    "        args=args,\n",
    "        train_dataset=block.train.dset,\n",
    "        eval_dataset=block.test.dset,\n",
    "        data_collator=block.collator,\n",
    "        compute_metrics=metric,\n",
    "    )\n",
    "    \n",
    "    mp.freeze_support()\n",
    "    learn.train()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
