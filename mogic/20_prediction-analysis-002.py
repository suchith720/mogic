# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/20_prediction-analysis.ipynb.

# %% auto 0
__all__ = ['display_momos']

# %% ../nbs/20_prediction-analysis.ipynb 2
import pandas as pd, os, pickle, numpy as np, torch, torch.nn.functional as F, scipy.sparse as sp, re
from scipy import sparse
from typing import List
from tqdm.auto import tqdm
from torch.utils.data import Dataset, DataLoader
from typing import Optional

from xcai.basics import *
from xcai.analysis import *

from xclib.utils.sparse import retain_topk
from xcai.models.distillation import TCH001
from xcai.models.classifiers import CLS001

from IPython.display import HTML,display

def get_query_lbl_text(query_text, lbl_text, pred_file, topk=3):
    pred = sp.load_npz(pred_file)
    pred = retain_topk(pred, k=topk)
    return [query_text[n]+",".join([lbl_text[i] for i in pred[n].indices]) for n in tqdm(range(pred.shape[0]))]

# def dump_example_text(fname, examples):
#     with open(fname, 'w') as file:
#         for example in examples:
#             for k,v in example.items():
#                 text = " :: ".join(v) if isinstance(v, list) else v
#                 file.write(f"{k} -> {text}\n")
#             file.write("\n")

def compare_examples(dset_1:Dataset, dset_2:Dataset, idxs:List):
    batch = [dset_1[i] for i in tqdm(idxs)]
    for x in batch:
        x['Query'] = x.pop('data_input_text')
        x['Pretrained LLaMA'] = x.pop('lbl2data_input_text')

    for i,x in zip(idxs, batch):
        x['Finetuned LLaMA'] = dset_2[i]['lbl2data_input_text']
    return batch

def dump_example_text(fname, examples):
    with open(fname, 'w') as file:
        pass

def get_examples(dset:Dataset, idxs:List, pat:str):
    return {k:v for k,v in dset.__getitems__(idxs).items() if re.match(k,pat)} 

# %% ../nbs/20_prediction-analysis.ipynb 7
if __name__ == '__main__':
    pkl_dir = "/home/aiscuser/scratch1/datasets"

    # """ Load data """
    # pkl_file = f'{pkl_dir}/processed/msmarco_data-entity1_distilbert-base-uncased_xcs.pkl'
    # with open(pkl_file, 'rb') as file: block = pickle.load(file)
    # block_1 = block.linker_dset('ent_meta', remove_empty=False)
    # print(f'Block 1 Labels: {block_1.n_lbl}')

    # pkl_file = f'{pkl_dir}/processed/msmarco_data-entity-llama4_distilbert-base-uncased_xcs.pkl'
    # with open(pkl_file, 'rb') as file: block = pickle.load(file)
    # block_2 = block.linker_dset('ent_meta', remove_empty=False)
    # print(f'Block 2 Labels: {block_2.n_lbl}')

    # assert block_1.train.dset.n_data == block_2.train.dset.n_data

    # """ Analysis """
    # pattern = r'^(data|lbl2data|ent2data)_input_text$'

    # dset_1 = TextColumns(block_1.train.dset, pat=pattern)
    # dset_2 = TextColumns(block_2.train.dset, pat=pattern)

    # """ finding examples """
    # idxs = np.random.permutation(block_1.train.dset.n_data)[:1000]
    # batch = get_batch(dset_1, dset_2, idxs)

    # dump_example_text('outputs/entity_comparison.txt', batch)

    # pkl_file = f'{pkl_dir}/processed/msmarco_data-entity_distilbert-base-uncased_xcs-qdoc.pkl'
    # with open(pkl_file, 'rb') as file: block = pickle.load(file)
    # block = block.linker_dset('ent_meta', remove_empty=False)
    # print(f'Block 2 Labels: {block_2.n_lbl}')

    pkl_file_1 = f'{pkl_dir}/processed/msmarco_data-entity1_distilbert-base-uncased_sxc-qdoc.pkl'
    with open(pkl_file_1, 'rb') as file: block = pickle.load(file)
    block_1 = block.linker_dset('ent_meta')
    print(f'Block Labels 1: {block_1.n_lbl}')

    pkl_file_2 = f'{pkl_dir}/processed/msmarco_data-entity1_distilbert-base-uncased_sxc.pkl'
    with open(pkl_file_2, 'rb') as file: block = pickle.load(file)
    block_2 = block.linker_dset('ent_meta')
    print(f'Block Labels 2: {block_2.n_lbl}')

    n_data = block_1.test.dset.n_data 
    assert n_data == block_2.test.dset.n_data, f'{block_1.test.dset.n_data} {block_2.test.dset.n_data}'

    pattern = r'^(data|lbl2data|ent2data)_input_text$'

    idxs = np.random.permutation(n_data)[:1000]
    batch_1 = get_examples(block_1.test.dset, idxs, pattern)
    batch_2 = get_examples(block_2.test.dset, idxs, pattern)

    breakpoint()

    dump_example_text('/data/to_suchith/comparison_of_linker_w_and_wo_predicted_labels.txt', batch)


